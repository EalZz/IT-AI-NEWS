import os
import datetime
from scraper.ai_times import get_latest_news as get_aitimes
from scraper.pytorch_kr import get_latest_news as get_pytorchkr
from summarizer.gemini import summarize_articles
from notifier.discord import send_message
from state_manager.memory import load_sent_articles, save_sent_articles
from dotenv import load_dotenv

# ë¡œì»¬(ê°œë°œí™˜ê²½) í…ŒìŠ¤íŠ¸ìš© í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì´ ìˆì„ ê²½ìš°)
load_dotenv()

def main():
    # í˜„ì¬ ì‹œê°„ í™•ì¸ (UTC 22ì‹œëŠ” KST 07ì‹œ 10ë¶„ ì‹¤í–‰ ì‹œì )
    now_utc = datetime.datetime.now(datetime.timezone.utc)
    is_morning_briefing = (now_utc.hour == 22)
    
    if is_morning_briefing:
        print("--- [ì‹œì‘] ì˜¤ì „ 7ì‹œ 10ë¶„ ì •ê¸° ë‰´ìŠ¤ ë¸Œë¦¬í•‘ ëª¨ë“œ ---")
    else:
        print("--- [ì‹œì‘] ì‹¤ì‹œê°„ ê¸‰ìƒìŠ¹ ë‰´ìŠ¤ ì—ì´ì „íŠ¸ ëª¨ë“œ (1ì‹œê°„ ì£¼ê¸°) ---")
        
    all_news = get_aitimes() + get_pytorchkr()
    
    # ìƒíƒœ íŒŒì¼ ë¡œë“œ
    hourly_sent_links = load_sent_articles("sent_articles.json")
    daily_sent_links = load_sent_articles("daily_sent_articles.json")
    
    if is_morning_briefing:
        new_articles = [news for news in all_news if news['link'] not in daily_sent_links]
        
        if not new_articles:
            print("[ì¢…ë£Œ] ì–´ì œ ì•„ì¹¨ ì´í›„ ìƒˆë¡­ê²Œ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ì–´ ë¸Œë¦¬í•‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
            
        print(f"--- [ì§„í–‰] ì´ {len(new_articles)}ê°œì˜ ìµœì‹  ë‰´ìŠ¤ì— ëŒ€í•´ ğŸŒ…ì•„ì¹¨ ë¸Œë¦¬í•‘ ìš”ì•½ì„ ìš”ì²­í•©ë‹ˆë‹¤ ---")
        summary_text = summarize_articles(new_articles, mode="daily")
        
        # ë°ì¼ë¦¬ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        daily_sent_links.extend([news['link'] for news in new_articles])
        save_sent_articles(daily_sent_links, "daily_sent_articles.json")
        
        # ì˜¤ì „ 8ì‹œì— ì½ì€ ê¸°ì‚¬ë“¤ì€ 9ì‹œì— ì¤‘ë³µìœ¼ë¡œ ì†ë³´ ì·¨ê¸‰ë˜ì§€ ì•Šë„ë¡ hourly ë©”ëª¨ë¦¬ì—ë„ ì¶”ê°€
        hourly_new = [news['link'] for news in new_articles if news['link'] not in hourly_sent_links]
        if hourly_new:
            hourly_sent_links.extend(hourly_new)
            save_sent_articles(hourly_sent_links, "sent_articles.json")
            
        if summary_text.startswith("ìš”ì•½ ì‹¤íŒ¨"):
            print(f"[ì¢…ë£Œ] ìš”ì•½ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë©”ì‹œì§€ ì „ì†¡ ìƒëµ.\nì‚¬ìœ : {summary_text}")
            return
            
        print("--- [ì„±ê³µ] ì•„ì¹¨ ë¸Œë¦¬í•‘ ìƒì„± ì™„ë£Œ. ì „ì†¡í•©ë‹ˆë‹¤ ---")
        send_message(summary_text)

    else:
        new_articles = [news for news in all_news if news['link'] not in hourly_sent_links]
        
        if not new_articles:
            print("[ì¢…ë£Œ] 1ì‹œê°„ ë™ì•ˆ ìƒˆë¡­ê²Œ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ì–´ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
            
        print(f"--- [ì§„í–‰] ì´ {len(new_articles)}ê°œì˜ ìƒˆë¡œìš´ ê¸°ì‚¬ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ì—ê²Œ ğŸ”¥ì¤‘ìš”ë„ í‰ê°€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤ ---")
        summary_text = summarize_articles(new_articles, mode="hourly")
        
        # ì‹œê°„ë‹¹ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        hourly_sent_links.extend([news['link'] for news in new_articles])
        save_sent_articles(hourly_sent_links, "sent_articles.json")
        
        if summary_text.startswith("ìš”ì•½ ì‹¤íŒ¨"):
            print(f"[ì¢…ë£Œ] ìš”ì•½ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë©”ì‹œì§€ ì „ì†¡ ìƒëµ.\nì‚¬ìœ : {summary_text}")
            return
            
        if summary_text.strip() == "SKIP":
            print("[ì¢…ë£Œ] AI ì—ì´ì „íŠ¸ íŒë‹¨ ê²°ê³¼: ì´ë²ˆ ê¸°ì‚¬ë“¤ì€ ì¤‘ìš”ë„ê°€ ë‚®ì•„ ì•Œë¦¼ì„ ë³´ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤. (SKIP)")
            return
            
        print("--- [ì„±ê³µ] íŠ¹ê¸‰ ì†ë³´ ìš”ì•½ ì™„ë£Œ. ë©”ì‹œì§€ ì „ì†¡ì„ ì‹œì‘í•©ë‹ˆë‹¤ ---")
        send_message(summary_text)

    print("--- [ì¢…ë£Œ] ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ë! ---")

if __name__ == "__main__":
    main()
